{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "from glob import glob\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seed for reproducible randomness\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A map of the gesture directories to their class names\n",
    "directory_map = {\n",
    "    'Brush_teeth': 'brush_teeth',\n",
    "    'Climb_stairs*': 'climb_stairs',\n",
    "    'Comb_hair': 'comb_hair',\n",
    "    'Descend_stairs': 'descend_stairs',\n",
    "    'Drink_glass*': 'drink_glass',\n",
    "    'Eat_meat': 'eat_meat',\n",
    "    'Eat_soup': 'eat_soup',\n",
    "    'Getup_bed*': 'getup_bed',\n",
    "    'Liedown_bed': 'liedown_bed',\n",
    "    'Pour_water*': 'pour_water',\n",
    "    'Sitdown_chair*': 'sitdown_chair',\n",
    "    'Standup_chair*': 'standup_chair',\n",
    "    'Use_telephone': 'use_telephone',\n",
    "    'Walk*': 'walk'\n",
    "}\n",
    "\n",
    "classes = list(directory_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_numpy(file):\n",
    "    \"\"\"Convert acceleration parameter .txt file to np.ndarray\"\"\"\n",
    "    with open(file) as f:\n",
    "        X = []\n",
    "        for line in f:\n",
    "            Ax, Ay, Az = line.strip('\\n').split()\n",
    "            X.append([float(Ax), float(Ay), float(Az)])\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = [], []\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00283/ADL_Dataset.zip'\n",
    "\n",
    "try:\n",
    "    # Download the dataset\n",
    "    path, zip_path = 'HMP_Dataset', 'ADL_Dataset.zip'\n",
    "    print('Downloading dataset from {} ...'.format(url))\n",
    "    response = requests.get(url)\n",
    "    with open(zip_path, 'wb') as f:\n",
    "        print('Writing {} ...'.format(zip_path))\n",
    "        f.write(response.content)\n",
    "    with ZipFile(zip_path, 'r') as zip_ref:\n",
    "        print('Extracting {} ...'.format(zip_path))\n",
    "        zip_ref.extractall()\n",
    "except:\n",
    "    raise\n",
    "else:\n",
    "    print('Reading data into Numpy arrays ...')\n",
    "    for pattern, label in directory_map.items():\n",
    "        for folder in glob(os.path.join(path, pattern)):\n",
    "            for txt in glob(os.path.join(folder, '*.txt')):\n",
    "                X.append(file_to_numpy(txt))\n",
    "                y.append(label)\n",
    "    print('Done!')\n",
    "finally:\n",
    "    os.remove(zip_path)\n",
    "    shutil.rmtree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation and test sets (65-20-15)\n",
    "X_train, X_rest, y_train, y_rest = train_test_split(X, y, test_size=0.35, shuffle=True, random_state=rng)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rest, y_rest, test_size=0.43, shuffle=True, random_state=rng)\n",
    "\n",
    "# Display the split sizes\n",
    "print('Training set size: {}'.format(len(y_train)))\n",
    "print('Validation set size: {}'.format(len(y_val)))\n",
    "print('Test set size: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signal(XX, figsize=(7, 4), title=None):\n",
    "    \"\"\"Visualize an accelerometer signal\"\"\"\n",
    "    title = 'Accelerometer signals' if title is None else title\n",
    "    labels = ['X', 'Y', 'Z']\n",
    "    colors = ['blue', 'red', 'green']\n",
    "    fig, axs = plt.subplots(3, 1, sharex=True, figsize=figsize)\n",
    "    for i, ax in enumerate(axs.flat):\n",
    "        ax.plot(XX[:, i], label=labels[i], color=colors[i])\n",
    "        ax.legend(loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0, wspace=0, top=0.92)\n",
    "    fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot some sample accelerometer signals from the training set\n",
    "for signal in X_train[:5]:\n",
    "    plot_signal(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequentia.preprocessing import Preprocess\n",
    "\n",
    "# Create a preprocessing pipeline\n",
    "pre = Preprocess()\n",
    "pre.standardize()\n",
    "pre.filtrate(n=5, method='median')\n",
    "pre.downsample(n=5, method='decimate')\n",
    "pre.fft()\n",
    "pre.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the same sample accelerometer signals, but preprocessed\n",
    "for signal in pre.transform(X_train[:5]):\n",
    "    plot_signal(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the preprocessing pipeline to each dataset split\n",
    "X_train, X_val, X_test = pre.transform(X_train), pre.transform(X_val), pre.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(acc, cm, dataset, labels):\n",
    "    \"\"\"Display accuracy and confusion matrix\"\"\"\n",
    "    df = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(df, annot=True)\n",
    "    plt.title('Confusion matrix for {} set predictions'.format(dataset), fontsize=14)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    # Fix for matplotlib bug that cuts off top/bottom of seaborn visualizations\n",
    "    b, t = plt.ylim()\n",
    "    plt.ylim(b + 0.5, t - 0.5)\n",
    "    plt.show()\n",
    "    print('Accuracy: {:.2f}%'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequentia.classifiers import DTWKNN\n",
    "\n",
    "# Fit a DTWKNN classifier on the training data\n",
    "clf = DTWKNN(k=3, radius=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Classify the validation examples and display accuracy and confusion matrix\n",
    "acc, cm = clf.evaluate(X_val, y_val, labels=classes, n_jobs=-1)\n",
    "show_results(acc, cm, dataset='validation', labels=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequentia.classifiers import HMM, HMMClassifier\n",
    "\n",
    "# Create HMMs to represent each class\n",
    "hmms = []\n",
    "for label in tqdm(classes, desc='Training HMMs'):\n",
    "    hmm = HMM(label=label, n_states=10, random_state=rng)\n",
    "    hmm.set_random_initial()\n",
    "    hmm.set_random_transitions()\n",
    "    hmm.fit([X_train[i] for i, y_i in enumerate(y_train) if y_i == label])\n",
    "    hmms.append(hmm)\n",
    "    \n",
    "# Fit a HMM classifier with the HMMs\n",
    "clf = HMMClassifier()\n",
    "clf.fit(hmms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Classify the validation examples and display accuracy and confusion matrix\n",
    "acc, cm = clf.evaluate(X_val, y_val, labels=classes)\n",
    "show_results(acc, cm, dataset='validation', labels=classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
